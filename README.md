# Sistema de AssistÃªncia Visual para Ambientes Educacionais

Um sistema inteligente de assistÃªncia visual que utiliza redes neurais convolucionais e reconhecimento de gestos para auxiliar pessoas com deficiÃªncia visual em ambientes educacionais.

## ğŸ¯ Sobre o Projeto

Este projeto desenvolve uma plataforma inovadora que combina detecÃ§Ã£o de objetos, reconhecimento de gestos e sÃ­ntese de voz para criar uma soluÃ§Ã£o completa de acessibilidade. O sistema detecta objetos educacionais comuns e fornece feedback auditivo sobre suas posiÃ§Ãµes espaciais, permitindo maior autonomia para pessoas com deficiÃªncia visual.

### âœ¨ CaracterÃ­sticas Principais

- **DetecÃ§Ã£o de Objetos Inteligente**: Utiliza YOLO11m para identificaÃ§Ã£o em tempo real de materiais escolares
- **Reconhecimento de Gestos Personalizado**: Sistema de cadastro de gestos especÃ­ficos via MediaPipe
- **Feedback Auditivo Natural**: SÃ­ntese de voz neural atravÃ©s da API Kokoro
- **LocalizaÃ§Ã£o Espacial**: Algoritmo de posicionamento que descreve a localizaÃ§Ã£o dos objetos
- **Interface Web Responsiva**: Frontend intuitivo otimizado para acessibilidade

## ğŸ—ï¸ Arquitetura do Sistema

### Frontend
- Interface HTML5 responsiva
- Captura de vÃ­deo via WebRTC
- Processamento de gestos em tempo real
- ComunicaÃ§Ã£o WebSocket bidirecional

### Backend
- Servidor WebSocket Python
- Modelo YOLO11m para detecÃ§Ã£o de objetos
- Processamento de coordenadas espaciais
- IntegraÃ§Ã£o com API de sÃ­ntese de voz

## ğŸš€ Performance

| MÃ©trica | YOLO11m (v2) | Melhoria vs v1 |
|---------|--------------|----------------|
| Tempo de InferÃªncia | ~30ms | 6.7x mais rÃ¡pido |
| Uso de VRAM | 2GB | 75% menos |
| mAP@0.5 | 0.89 | 24% maior |
| FPS | ~33 FPS | 6.6x mais rÃ¡pido |

## ğŸ“‹ PrÃ©-requisitos

### Sistema
- Python 3.8+
- NVIDIA GPU (recomendado) ou CPU
- Webcam
- Navegador Chrome/Chromium

### Hardware Testado
- GPU: NVIDIA RTX 4080 Super (16GB VRAM)
- CPU: AMD Ryzen 7 9700X
- RAM: 64GB
- OS: Ubuntu 24.04 LTS

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio
```bash
git clone <repository-url>
cd visual_assistance
```

### 2. Configurar Backend
```bash
cd backend
pip install -r requirements.txt
```

### 3. Configurar SÃ­ntese de Voz (Docker)
```bash
# Para CPU
docker run -p 8880:8880 ghcr.io/remsky/kokoro-fastapi-cpu:latest

# Para GPU NVIDIA
docker run --gpus all -p 8880:8880 ghcr.io/remsky/kokoro-fastapi-gpu:latest
```

### 4. Baixar Modelos YOLO
```bash
cd backend
# Os modelos yolo11m.pt e yolov8m.pt devem estar na pasta backend/
```

## ğŸš€ Como Usar

### 1. Iniciar o Backend
```bash
cd backend
python main.py
```

### 2. Abrir o Frontend
```bash
cd frontend
# Abrir main.html no navegador Chrome/Chromium
```

### 3. Funcionalidades

#### DetecÃ§Ã£o de Objetos
- O sistema detecta automaticamente objetos educacionais
- Fornece descriÃ§Ã£o auditiva da localizaÃ§Ã£o (ex: "caderno na esquerda meio")
- Suporte para: livros, cadernos, canetas, lÃ¡pis, mochilas, laptops, etc.

#### Cadastro de Gestos
1. Digite o nome do objeto no campo "Nome do Objeto"
2. Clique em "Capturar Sinal"
3. FaÃ§a o gesto desejado na frente da cÃ¢mera
4. Clique em "Cadastrar Sinal" para salvar

#### Busca por Gestos
- FaÃ§a um gesto cadastrado para buscar objetos especÃ­ficos
- O sistema fornecerÃ¡ feedback auditivo sobre a localizaÃ§Ã£o do objeto

## ğŸ”§ ConfiguraÃ§Ã£o

### Ajustar ConfianÃ§a de DetecÃ§Ã£o
No arquivo `backend/main.py`:
```python
detector = ClassroomObjectDetector(
    model_path='yolo11m.pt',
    confidence_threshold=0.7  # Ajustar entre 0.1-0.9
)
```

### Modelos DisponÃ­veis
- `yolo11m.pt`: Balanceado (recomendado)
- `yolov8n.pt`: Mais rÃ¡pido (hardware limitado)
- `yolov8m.pt`: Maior precisÃ£o

## ğŸ“Š Objetos DetectÃ¡veis

### COCO Dataset (PrÃ©-treinado)
âœ… Pessoa, cadeira, mesa, laptop, livro, mochila, mouse, teclado, celular, garrafa, xÃ­cara, TV, maÃ§Ã£, banana

### Objetos Personalizados (v1 - Dataset Customizado)
âœ… Caneta, lÃ¡pis, borracha, apontador, estojo, caderno especÃ­fico, rÃ©gua, calculadora, tesoura

## ğŸŒ Compatibilidade

- **Navegadores Testados**: Chrome, Chromium
- **Sistema Operacional**: Linux (testado), Windows, macOS
- **Hardware**: CPU (funcional) ou GPU NVIDIA (recomendado)

## ğŸ¨ Interface

A interface apresenta:
- VisualizaÃ§Ã£o simultÃ¢nea da cÃ¢mera original e detecÃ§Ãµes
- Painel para cadastro de novos gestos
- Lista de gestos cadastrados
- Indicadores de status do sistema
- Feedback visual das detecÃ§Ãµes

## ğŸ“ˆ Algoritmo de Posicionamento

O sistema divide a tela em uma grade 3x3:
```
esquerda_frente | centro_frente | direita_frente
esquerda_meio   | centro_meio   | direita_meio
esquerda_fundo  | centro_fundo  | direita_fundo
```

## ğŸ§ª Casos de Uso Validados

- **LocalizaÃ§Ã£o de Material Escolar**: IdentificaÃ§Ã£o de canetas, lÃ¡pis, borrachas
- **OrganizaÃ§Ã£o de Mesa**: DetecÃ§Ã£o de livros, cadernos, calculadoras
- **NavegaÃ§Ã£o em Sala**: IdentificaÃ§Ã£o de laptops, mochilas, garrafas
- **InteraÃ§Ã£o por Gestos**: Busca direcionada atravÃ©s de gestos personalizados

## âš¡ MÃ©tricas de Performance

- **DetecÃ§Ã£o de objetos**: <50ms por frame
- **Reconhecimento de gestos**: <100ms
- **SÃ­ntese de voz**: <200ms
- **Tempo total de resposta**: <500ms
- **PrecisÃ£o de localizaÃ§Ã£o**: >90% de sucesso

## ğŸ”¬ Dados TÃ©cnicos

### Dataset de Treinamento (v1)
- 18 datasets do Roboflow
- 24.794 imagens totais
- 63.912 anotaÃ§Ãµes
- Objetos educacionais diversos

### EvoluÃ§Ã£o do Projeto
- **v1**: MobileNetSSD com treinamento customizado (48h+)
- **v2**: YOLO11m prÃ©-treinado (otimizado)

## ğŸ¤ Contribuidores

- Gabriel GonÃ§alves ([gonntt](https://github.com/gonntt))
- Marco AntÃ´nio ([macostacurta](https://github.com/macostacurta))
- Vinicius Gomes ([vini-gm](https://github.com/vini-gm/))
- Victor Laurentino ([PitzTech](https://github.com/PitzTech))

## ğŸ“ Contexto AcadÃªmico

Este projeto foi desenvolvido como parte do trabalho final do curso, representando uma implementaÃ§Ã£o prÃ¡tica de tecnologias de IA para acessibilidade educacional. O sistema demonstra a integraÃ§Ã£o efetiva de mÃºltiplas tecnologias emergentes para resolver desafios reais de inclusÃ£o.

## ğŸ”® Trabalhos Futuros

- ExpansÃ£o para dispositivos mÃ³veis
- Suporte a mais navegadores
- DetecÃ§Ã£o 3D com informaÃ§Ãµes de profundidade
- Reconhecimento de texto (OCR)
- NavegaÃ§Ã£o indoor avanÃ§ada
- Aprendizado adaptativo personalizado

## ğŸ“ LimitaÃ§Ãµes Conhecidas

- DependÃªncia de boa iluminaÃ§Ã£o
- Dificuldades com objetos parcialmente obstruÃ­dos
- Compatibilidade limitada a navegadores Chromium
- Necessidade de hardware adequado para performance Ã³tima

## ğŸ“„ LicenÃ§a

Este projeto Ã© desenvolvido para fins acadÃªmicos e de pesquisa em acessibilidade.

---

**Sistema de AssistÃªncia Visual** - Promovendo autonomia e inclusÃ£o atravÃ©s da tecnologia.
